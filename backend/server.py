from fastapi import FastAPI, APIRouter, HTTPException
from dotenv import load_dotenv
from starlette.middleware.cors import CORSMiddleware
from motor.motor_asyncio import AsyncIOMotorClient
import os
import logging
from pathlib import Path
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import uuid
from datetime import datetime, timedelta
import asyncio
import json
import random
import math
import numpy as np
import pandas as pd
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, mean_squared_error
import pickle
import warnings
warnings.filterwarnings('ignore')

# Load environment variables
ROOT_DIR = Path(__file__).parent
load_dotenv(ROOT_DIR / '.env')

# MongoDB connection
mongo_url = os.environ['MONGO_URL']
client = AsyncIOMotorClient(mongo_url)
db = client[os.environ['DB_NAME']]

# Create the main app without a prefix
app = FastAPI(title="Traffic Flow Optimization API")

# Create a router with the /api prefix
api_router = APIRouter(prefix="/api")

# Models
class TrafficData(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    intersection_id: str
    city: str  # "Accra" or "Kumasi"
    location: Dict[str, float]  # {"lat": x, "lng": y}
    vehicle_count: int
    average_speed: float
    congestion_level: str  # "Low", "Medium", "High", "Critical"
    timestamp: datetime = Field(default_factory=datetime.utcnow)
    weather_condition: Optional[str] = "Clear"

class RouteRequest(BaseModel):
    start_location: Dict[str, float]  # {"lat": x, "lng": y}
    end_location: Dict[str, float]
    city: str
    vehicle_type: str = "car"
    departure_time: Optional[datetime] = None

class RouteRecommendation(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    route_id: str
    path_coordinates: List[Dict[str, float]]
    estimated_duration: int  # minutes
    estimated_distance: float  # km
    traffic_conditions: str
    alternative_routes: List[Dict[str, Any]]
    ai_insights: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class TrafficPattern(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    city: str
    time_period: str  # "morning_rush", "evening_rush", "midday", "night"
    congestion_hotspots: List[Dict[str, Any]]
    average_speeds: Dict[str, float]
    predictions: Dict[str, Any]  # AI predictions
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class SignalOptimization(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    intersection_id: str
    city: str
    current_timing: Dict[str, int]  # signal phases and durations
    optimized_timing: Dict[str, int]
    expected_improvement: float  # percentage
    ai_reasoning: str
    ml_confidence: float  # ML model confidence score
    timestamp: datetime = Field(default_factory=datetime.utcnow)

class TrafficPrediction(BaseModel):
    id: str = Field(default_factory=lambda: str(uuid.uuid4()))
    city: str
    intersection_id: str
    prediction_horizon: int  # minutes into future
    predicted_congestion: str  # "Low", "Medium", "High", "Critical"
    predicted_vehicle_count: int
    predicted_speed: float
    confidence_score: float  # ML model confidence
    ml_model_used: str
    timestamp: datetime = Field(default_factory=datetime.utcnow)

# ML Traffic Prediction Engine
class TrafficMLEngine:
    def __init__(self):
        self.traffic_model = None
        self.speed_model = None
        self.congestion_model = None
        self.scaler = StandardScaler()
        self.is_trained = False
        self.model_accuracy = {}
        
    def generate_training_data(self, city: str, days: int = 30) -> pd.DataFrame:
        """Generate synthetic training data for ML models"""
        data = []
        intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
        
        # Generate data for the past 30 days
        for day in range(days):
            date = datetime.now() - timedelta(days=day)
            
            for hour in range(24):
                for intersection in intersections:
                    # Time-based features
                    is_weekend = date.weekday() >= 5
                    is_rush_hour = hour in [7, 8, 17, 18, 19]
                    is_morning = 6 <= hour <= 11
                    is_evening = 17 <= hour <= 21
                    
                    # Weather simulation (simplified)
                    weather_impact = random.choice([0, 0.1, 0.2, 0.3])  # 0=clear, 0.3=heavy rain
                    
                    # Base traffic calculation
                    base_traffic = 30
                    if is_rush_hour:
                        base_traffic *= random.uniform(2.5, 4.0)
                    elif is_morning or is_evening:
                        base_traffic *= random.uniform(1.5, 2.0)
                    elif is_weekend:
                        base_traffic *= random.uniform(0.7, 1.2)
                    
                    # Add weather impact
                    base_traffic *= (1 + weather_impact)
                    
                    # Speed calculation (inverse relationship with traffic)
                    base_speed = max(10, 50 - (base_traffic - 30) * 0.8)
                    base_speed *= random.uniform(0.8, 1.2)  # Add randomness
                    
                    # Congestion level
                    if base_traffic > 80:
                        congestion = 3  # Critical
                    elif base_traffic > 60:
                        congestion = 2  # High
                    elif base_traffic > 40:
                        congestion = 1  # Medium
                    else:
                        congestion = 0  # Low
                    
                    data.append({
                        'intersection_id': intersection['id'],
                        'hour': hour,
                        'day_of_week': date.weekday(),
                        'is_weekend': int(is_weekend),
                        'is_rush_hour': int(is_rush_hour),
                        'is_morning': int(is_morning),
                        'is_evening': int(is_evening),
                        'weather_impact': weather_impact,
                        'vehicle_count': int(base_traffic),
                        'average_speed': base_speed,
                        'congestion_level': congestion,
                        'latitude': intersection['lat'],
                        'longitude': intersection['lng']
                    })
        
        return pd.DataFrame(data)
    
    def train_models(self, city: str):
        """Train ML models for traffic prediction"""
        logger.info(f"Training ML models for {city}...")
        
        # Generate training data
        df = self.generate_training_data(city)
        
        # Feature engineering
        features = ['hour', 'day_of_week', 'is_weekend', 'is_rush_hour', 
                   'is_morning', 'is_evening', 'weather_impact', 'latitude', 'longitude']
        
        X = df[features]
        
        # Scale features
        X_scaled = self.scaler.fit_transform(X)
        
        # Train traffic volume prediction model
        y_traffic = df['vehicle_count']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_traffic, test_size=0.2, random_state=42)
        
        self.traffic_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.traffic_model.fit(X_train, y_train)
        
        traffic_pred = self.traffic_model.predict(X_test)
        traffic_mae = mean_absolute_error(y_test, traffic_pred)
        self.model_accuracy['traffic_mae'] = traffic_mae
        
        # Train speed prediction model
        y_speed = df['average_speed']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_speed, test_size=0.2, random_state=42)
        
        self.speed_model = RandomForestRegressor(n_estimators=100, random_state=42)
        self.speed_model.fit(X_train, y_train)
        
        speed_pred = self.speed_model.predict(X_test)
        speed_mae = mean_absolute_error(y_test, speed_pred)
        self.model_accuracy['speed_mae'] = speed_mae
        
        # Train congestion classification model
        y_congestion = df['congestion_level']
        X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_congestion, test_size=0.2, random_state=42)
        
        self.congestion_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
        self.congestion_model.fit(X_train, y_train)
        
        congestion_pred = self.congestion_model.predict(X_test)
        congestion_mae = mean_absolute_error(y_test, congestion_pred)
        self.model_accuracy['congestion_mae'] = congestion_mae
        
        self.is_trained = True
        logger.info(f"ML models trained successfully for {city}")
        logger.info(f"Model accuracies: {self.model_accuracy}")
    
    def predict_traffic(self, city: str, intersection_id: str, prediction_horizon: int = 60) -> TrafficPrediction:
        """Predict traffic conditions for a specific intersection"""
        if not self.is_trained:
            self.train_models(city)
        
        # Get intersection details
        intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
        intersection = next((i for i in intersections if i['id'] == intersection_id), None)
        
        if not intersection:
            raise ValueError(f"Intersection {intersection_id} not found")
        
        # Prepare features for prediction
        future_time = datetime.now() + timedelta(minutes=prediction_horizon)
        hour = future_time.hour
        day_of_week = future_time.weekday()
        is_weekend = day_of_week >= 5
        is_rush_hour = hour in [7, 8, 17, 18, 19]
        is_morning = 6 <= hour <= 11
        is_evening = 17 <= hour <= 21
        weather_impact = random.uniform(0, 0.2)  # Simplified weather prediction
        
        features = np.array([[
            hour, day_of_week, int(is_weekend), int(is_rush_hour),
            int(is_morning), int(is_evening), weather_impact,
            intersection['lat'], intersection['lng']
        ]])
        
        features_scaled = self.scaler.transform(features)
        
        # Make predictions
        predicted_vehicles = max(0, int(self.traffic_model.predict(features_scaled)[0]))
        predicted_speed = max(5, self.speed_model.predict(features_scaled)[0])
        predicted_congestion_level = max(0, min(3, int(round(self.congestion_model.predict(features_scaled)[0]))))
        
        congestion_labels = ["Low", "Medium", "High", "Critical"]
        predicted_congestion = congestion_labels[predicted_congestion_level]
        
        # Calculate confidence score based on model accuracy
        confidence = 1.0 - (self.model_accuracy.get('traffic_mae', 10) / 100)
        confidence = max(0.5, min(1.0, confidence))
        
        return TrafficPrediction(
            city=city,
            intersection_id=intersection_id,
            prediction_horizon=prediction_horizon,
            predicted_congestion=predicted_congestion,
            predicted_vehicle_count=predicted_vehicles,
            predicted_speed=predicted_speed,
            confidence_score=confidence,
            ml_model_used="GradientBoosting+RandomForest Ensemble"
        )
    
    def optimize_signal_timing(self, intersection_id: str, current_traffic: TrafficData, city: str) -> Dict:
        """ML-based signal timing optimization"""
        if not self.is_trained:
            self.train_models(city)
        
        # Current signal timing (baseline)
        current_timing = {
            "north_south_green": 45,
            "north_south_yellow": 5,
            "east_west_green": 35,
            "east_west_yellow": 5,
            "pedestrian_phase": 15
        }
        
        # ML-based optimization algorithm
        traffic_intensity = current_traffic.vehicle_count / 100.0  # Normalize
        speed_factor = (50 - current_traffic.average_speed) / 50.0  # Normalize
        
        # Predict optimal timing using traffic patterns
        if current_traffic.congestion_level == "Critical":
            # Increase main direction time significantly
            optimization_factor = 1.5 + (traffic_intensity * 0.3)
            main_direction_time = min(70, int(45 * optimization_factor))
            secondary_direction_time = max(20, int(35 / optimization_factor))
            pedestrian_time = max(8, int(15 / optimization_factor))
            improvement = 30.0 + (traffic_intensity * 10)
            
        elif current_traffic.congestion_level == "High":
            optimization_factor = 1.2 + (traffic_intensity * 0.2)
            main_direction_time = min(60, int(45 * optimization_factor))
            secondary_direction_time = max(25, int(35 / optimization_factor))
            pedestrian_time = max(10, int(15 / optimization_factor))
            improvement = 20.0 + (traffic_intensity * 8)
            
        else:
            # Minor optimization for medium/low traffic
            optimization_factor = 1.0 + (speed_factor * 0.1)
            main_direction_time = int(45 * optimization_factor)
            secondary_direction_time = int(35 / optimization_factor)
            pedestrian_time = int(15 / optimization_factor)
            improvement = 5.0 + (speed_factor * 5)
        
        optimized_timing = {
            "north_south_green": main_direction_time,
            "north_south_yellow": 5,
            "east_west_green": secondary_direction_time,
            "east_west_yellow": 5,
            "pedestrian_phase": pedestrian_time
        }
        
        # Calculate ML confidence
        ml_confidence = min(0.95, 0.7 + (traffic_intensity * 0.2))
        
        reasoning = f"ML optimization based on traffic intensity {traffic_intensity:.2f} and speed factor {speed_factor:.2f}. " \
                   f"Optimized for {current_traffic.congestion_level.lower()} congestion conditions in {city}."
        
        return {
            "optimized_timing": optimized_timing,
            "expected_improvement": improvement,
            "ml_confidence": ml_confidence,
            "reasoning": reasoning
        }

# Global ML engine instance
ml_engine = TrafficMLEngine()

# Initialize AI Integration (will be set up when emergentintegrations is installed)
ai_chat = None

# Initialize Gemini AI Chat
async def initialize_ai_chat():
    """Initialize Gemini AI chat for traffic analysis"""
    global ai_chat
    try:
        from emergentintegrations.llm.chat import LlmChat
        
        api_key = os.environ.get('GEMINI_API_KEY')
        if api_key:
            ai_chat = LlmChat(
                api_key=api_key,
                session_id="traffic_optimization_system",
                system_message="""You are an expert AI traffic optimization specialist for Ghana, specifically for Accra and Kumasi cities. 
                Analyze traffic patterns, provide intelligent route recommendations, and suggest traffic management strategies.
                Focus on reducing congestion, improving traffic flow, and enhancing overall transportation efficiency.
                Provide practical, actionable insights based on real-world traffic conditions in Ghana."""
            ).with_model("gemini", "gemini-2.0-flash")
            logger.info("Gemini AI chat initialized successfully")
        else:
            logger.warning("GEMINI_API_KEY not found in environment")
    except Exception as e:
        logger.error(f"Failed to initialize AI chat: {e}")

async def get_ai_traffic_insights(traffic_data: List[TrafficData], city: str) -> str:
    """Get AI insights for traffic data"""
    global ai_chat
    
    if not ai_chat:
        return f"AI analysis not available. Current traffic in {city} shows mixed conditions with some congestion points."
    
    try:
        from emergentintegrations.llm.chat import UserMessage
        
        # Prepare traffic data summary for AI analysis
        traffic_summary = {
            "city": city,
            "total_intersections": len(traffic_data),
            "average_speed": sum(d.average_speed for d in traffic_data) / len(traffic_data),
            "congestion_levels": [d.congestion_level for d in traffic_data],
            "high_traffic_areas": [
                {
                    "intersection": d.intersection_id,
                    "vehicles": d.vehicle_count,
                    "speed": d.average_speed,
                    "level": d.congestion_level
                } for d in traffic_data if d.congestion_level in ["High", "Critical"]
            ]
        }
        
        prompt = f"""Analyze the current traffic situation in {city}, Ghana:

Traffic Data Summary:
- Total monitored intersections: {traffic_summary['total_intersections']}
- Average traffic speed: {traffic_summary['average_speed']:.1f} km/h
- Congestion distribution: {dict([(level, traffic_summary['congestion_levels'].count(level)) for level in set(traffic_summary['congestion_levels'])])}

High congestion areas:
{json.dumps(traffic_summary['high_traffic_areas'], indent=2)}

Please provide:
1. Overall traffic assessment for {city}
2. Top 3 specific recommendations for traffic authorities
3. Predicted traffic patterns for the next 2 hours
4. Emergency interventions needed (if any)

Keep recommendations practical and specific to Ghana's traffic management capabilities."""

        user_message = UserMessage(text=prompt)
        response = await ai_chat.send_message(user_message)
        
        return response.strip()
        
    except Exception as e:
        logger.error(f"AI analysis failed: {e}")
        return f"AI analysis temporarily unavailable. Based on current data, {city} shows {'high' if len([d for d in traffic_data if d.congestion_level in ['High', 'Critical']]) > 2 else 'moderate'} congestion levels."

async def get_ai_route_optimization(start: Dict, end: Dict, city: str, current_traffic: List[TrafficData]) -> str:
    """Get AI-powered route optimization insights"""
    global ai_chat
    
    if not ai_chat:
        return f"Route optimized using standard algorithms. Avoid main roads during peak hours in {city}."
    
    try:
        from emergentintegrations.llm.chat import UserMessage
        
        # Calculate distance and identify nearby intersections
        route_distance = math.sqrt((end["lat"] - start["lat"])**2 + (end["lng"] - start["lng"])**2) * 111
        
        # Find intersections along the route (simplified)
        nearby_traffic = [
            d for d in current_traffic 
            if abs(d.location["lat"] - (start["lat"] + end["lat"])/2) < 0.01 
            and abs(d.location["lng"] - (start["lng"] + end["lng"])/2) < 0.01
        ]
        
        prompt = f"""Optimize a route in {city}, Ghana from coordinates ({start['lat']:.4f}, {start['lng']:.4f}) to ({end['lat']:.4f}, {end['lng']:.4f}).

Route Information:
- Estimated distance: {route_distance:.2f} km
- Current time: {datetime.now().strftime('%H:%M')}
- Day: {datetime.now().strftime('%A')}

Nearby Traffic Conditions:
{json.dumps([{'intersection': d.intersection_id, 'vehicles': d.vehicle_count, 'speed': d.average_speed, 'congestion': d.congestion_level} for d in nearby_traffic], indent=2)}

Provide specific routing advice:
1. Recommended route strategy
2. Expected travel time considering current traffic
3. Alternative routes to avoid congestion
4. Best departure time if delaying is possible
5. Specific roads/areas to avoid in {city}

Focus on practical advice for drivers in Ghana."""

        user_message = UserMessage(text=prompt)
        response = await ai_chat.send_message(user_message)
        
        return response.strip()
        
    except Exception as e:
        logger.error(f"AI route optimization failed: {e}")
        return f"Route optimization completed. Current conditions in {city} suggest allowing extra time due to traffic patterns."

# Simulated traffic data for Accra and Kumasi
ACCRA_INTERSECTIONS = [
    {"id": "ACC_001", "name": "37 Military Hospital Junction", "lat": 5.5600, "lng": -0.1969},
    {"id": "ACC_002", "name": "Kwame Nkrumah Circle", "lat": 5.5566, "lng": -0.1969},
    {"id": "ACC_003", "name": "Kaneshie Market Junction", "lat": 5.5593, "lng": -0.2532},
    {"id": "ACC_004", "name": "Achimota Junction", "lat": 5.6037, "lng": -0.2267},
    {"id": "ACC_005", "name": "Tema Station Junction", "lat": 5.5500, "lng": -0.1969}
]

KUMASI_INTERSECTIONS = [
    {"id": "KUM_001", "name": "Kejetia Market Junction", "lat": 6.6885, "lng": -1.6244},
    {"id": "KUM_002", "name": "Tech Junction", "lat": 6.6745, "lng": -1.5716},
    {"id": "KUM_003", "name": "Adum Junction", "lat": 6.6961, "lng": -1.6208},
    {"id": "KUM_004", "name": "Asafo Market Junction", "lat": 6.7080, "lng": -1.6165},
    {"id": "KUM_005", "name": "Airport Roundabout", "lat": 6.7144, "lng": -1.5900}
]

def generate_realistic_traffic_data(city: str) -> List[TrafficData]:
    """Generate realistic traffic data for simulation"""
    intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
    traffic_data = []
    
    current_hour = datetime.now().hour
    
    for intersection in intersections:
        # Rush hour logic (7-9 AM, 5-7 PM)
        if current_hour in [7, 8, 17, 18]:
            congestion_multiplier = random.uniform(2.0, 3.5)
            congestion_level = random.choice(["High", "Critical"])
        elif current_hour in [9, 10, 16, 19]:
            congestion_multiplier = random.uniform(1.3, 2.0)
            congestion_level = "Medium"
        else:
            congestion_multiplier = random.uniform(0.5, 1.2)
            congestion_level = random.choice(["Low", "Medium"])
        
        vehicle_count = int(random.uniform(20, 80) * congestion_multiplier)
        avg_speed = max(5, random.uniform(15, 45) / congestion_multiplier)
        
        traffic_data.append(TrafficData(
            intersection_id=intersection["id"],
            city=city,
            location={"lat": intersection["lat"], "lng": intersection["lng"]},
            vehicle_count=vehicle_count,
            average_speed=avg_speed,
            congestion_level=congestion_level,
            weather_condition=random.choice(["Clear", "Cloudy", "Rainy"])
        ))
    
    return traffic_data

def calculate_route_optimization(start: Dict, end: Dict, city: str) -> RouteRecommendation:
    """AI-powered route optimization"""
    # Simulate AI route calculation
    distance = math.sqrt((end["lat"] - start["lat"])**2 + (end["lng"] - start["lng"])**2) * 111  # rough km conversion
    
    # Generate path coordinates (simplified)
    path_coords = [
        start,
        {"lat": (start["lat"] + end["lat"]) / 2, "lng": (start["lng"] + end["lng"]) / 2},
        end
    ]
    
    # Current hour affects duration
    current_hour = datetime.now().hour
    base_duration = distance * 2  # base minutes per km
    
    if current_hour in [7, 8, 17, 18]:  # Rush hours
        duration_multiplier = random.uniform(2.0, 3.0)
        traffic_condition = "Heavy Traffic"
    elif current_hour in [9, 10, 16, 19]:
        duration_multiplier = random.uniform(1.3, 1.8)
        traffic_condition = "Moderate Traffic"
    else:
        duration_multiplier = random.uniform(0.8, 1.2)
        traffic_condition = "Light Traffic"
    
    estimated_duration = int(base_duration * duration_multiplier)
    
    # Generate alternative routes
    alternatives = []
    for i in range(2):
        alt_duration = int(estimated_duration * random.uniform(1.1, 1.4))
        alternatives.append({
            "route_name": f"Alternative Route {i+1}",
            "duration": alt_duration,
            "distance": round(distance * random.uniform(1.05, 1.25), 2),
            "traffic_level": random.choice(["Moderate", "Heavy"])
        })
    
    ai_insights = f"Based on current traffic patterns in {city}, this route avoids major congestion points. " \
                 f"Traffic is {traffic_condition.lower()} at this time. " \
                 f"Consider alternative routes if traveling during rush hours."
    
    return RouteRecommendation(
        route_id=str(uuid.uuid4()),
        path_coordinates=path_coords,
        estimated_duration=estimated_duration,
        estimated_distance=round(distance, 2),
        traffic_conditions=traffic_condition,
        alternative_routes=alternatives,
        ai_insights=ai_insights
    )

# API Routes
@api_router.get("/")
async def root():
    return {"message": "Traffic Flow Optimization API", "status": "active"}

@api_router.get("/traffic/current/{city}")
async def get_current_traffic(city: str):
    """Get current traffic conditions for a city"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    traffic_data = generate_realistic_traffic_data(city)
    
    # Store in database
    for data in traffic_data:
        await db.traffic_data.insert_one(data.dict())
    
    return {
        "city": city,
        "traffic_data": [data.dict() for data in traffic_data],
        "summary": {
            "total_intersections": len(traffic_data),
            "high_congestion": len([d for d in traffic_data if d.congestion_level in ["High", "Critical"]]),
            "average_speed": round(sum(d.average_speed for d in traffic_data) / len(traffic_data), 2)
        }
    }

@api_router.post("/route/optimize")
async def optimize_route(request: RouteRequest):
    """Get AI-optimized route recommendation"""
    if request.city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    route_recommendation = calculate_route_optimization(
        request.start_location, 
        request.end_location, 
        request.city
    )
    
    # Store in database
    await db.route_recommendations.insert_one(route_recommendation.dict())
    
    return route_recommendation.dict()

@api_router.get("/analytics/patterns/{city}")
async def get_traffic_patterns(city: str):
    """Get AI-analyzed traffic patterns"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    # Generate AI insights for traffic patterns
    current_hour = datetime.now().hour
    
    if current_hour in [7, 8, 9]:
        time_period = "morning_rush"
        insights = "Morning rush hour pattern detected. Major congestion expected at commercial areas."
    elif current_hour in [17, 18, 19]:
        time_period = "evening_rush"
        insights = "Evening rush hour pattern. Heavy traffic from business districts to residential areas."
    elif current_hour in [12, 13, 14]:
        time_period = "midday"
        insights = "Midday traffic patterns. Moderate congestion around markets and commercial centers."
    else:
        time_period = "off_peak"
        insights = "Off-peak hours. Generally smooth traffic flow with occasional delays."
    
    intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
    hotspots = []
    
    for intersection in intersections[:3]:  # Top 3 hotspots
        congestion_score = random.uniform(0.6, 0.95) if time_period in ["morning_rush", "evening_rush"] else random.uniform(0.2, 0.6)
        hotspots.append({
            "intersection_id": intersection["id"],
            "name": intersection["name"],
            "location": {"lat": intersection["lat"], "lng": intersection["lng"]},
            "congestion_score": round(congestion_score, 2),
            "predicted_delay": int(congestion_score * 15)  # minutes
        })
    
    pattern = TrafficPattern(
        city=city,
        time_period=time_period,
        congestion_hotspots=hotspots,
        average_speeds={
            "main_roads": random.uniform(20, 40),
            "secondary_roads": random.uniform(25, 45),
            "residential": random.uniform(30, 50)
        },
        predictions={
            "next_hour_congestion": random.choice(["Increasing", "Stable", "Decreasing"]),
            "peak_time": "17:30" if time_period != "evening_rush" else "18:30",
            "ai_insights": insights
        }
    )
    
    # Store in database
    await db.traffic_patterns.insert_one(pattern.dict())
    
    return pattern.dict()

@api_router.get("/dashboard/overview/{city}")
async def get_dashboard_overview(city: str):
    """Get comprehensive dashboard data for traffic authorities"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    # Get current traffic data
    traffic_data = generate_realistic_traffic_data(city)
    
    # Calculate metrics
    total_vehicles = sum(d.vehicle_count for d in traffic_data)
    avg_speed = sum(d.average_speed for d in traffic_data) / len(traffic_data)
    critical_intersections = [d for d in traffic_data if d.congestion_level == "Critical"]
    high_congestion = [d for d in traffic_data if d.congestion_level in ["High", "Critical"]]
    
    # Get AI insights
    ai_insights = await get_ai_traffic_insights(traffic_data, city)
    
    # AI recommendations based on analysis
    ai_recommendations = []
    if len(critical_intersections) > 0:
        ai_recommendations.append("ðŸš¨ Deploy traffic controllers to critical intersections immediately")
        ai_recommendations.append("ðŸ“¢ Issue traffic alerts via radio and mobile apps")
    
    if avg_speed < 20:
        ai_recommendations.append("ðŸš¦ Implement dynamic signal timing optimization")
        ai_recommendations.append("ðŸšŒ Increase public transport frequency to reduce private vehicle load")
    
    if len(high_congestion) > 3:
        ai_recommendations.append("ðŸ”„ Activate alternative route guidance systems")
        ai_recommendations.append("ðŸ‘® Consider manual traffic direction at hotspots")
    
    if not ai_recommendations:
        ai_recommendations.append("âœ… Traffic flow is optimal. Maintain current monitoring.")
    
    overview = {
        "city": city,
        "timestamp": datetime.utcnow().isoformat(),
        "metrics": {
            "total_vehicles": total_vehicles,
            "average_speed": round(avg_speed, 2),
            "congestion_level": "Critical" if len(critical_intersections) > 2 else "High" if len(high_congestion) > 3 else "Moderate",
            "active_intersections": len(traffic_data),
            "critical_intersections": len(critical_intersections)
        },
        "hotspots": [
            {
                "intersection_id": d.intersection_id,
                "location": d.location,
                "congestion_level": d.congestion_level,
                "vehicle_count": d.vehicle_count,
                "average_speed": d.average_speed
            } for d in high_congestion
        ],
        "ai_recommendations": ai_recommendations,
        "ai_detailed_analysis": ai_insights,
        "predictions": {
            "next_hour": "Traffic expected to " + random.choice(["increase by 15%", "decrease by 10%", "remain stable"]),
            "rush_hour_impact": "High impact expected during 17:00-19:00",
            "weather_impact": "No significant weather-related delays expected"
        }
    }
    
    return overview

@api_router.post("/signals/optimize/{intersection_id}")
async def optimize_traffic_signals(intersection_id: str, city: str):
    """AI + ML powered traffic signal optimization"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    # Get current traffic data for the intersection
    traffic_data = generate_realistic_traffic_data(city)
    intersection_data = next((d for d in traffic_data if d.intersection_id == intersection_id), None)
    
    if not intersection_data:
        raise HTTPException(status_code=404, detail="Intersection not found")
    
    # Current signal timing (baseline)
    current_timing = {
        "north_south_green": 45,
        "north_south_yellow": 5,
        "east_west_green": 35,
        "east_west_yellow": 5,
        "pedestrian_phase": 15
    }
    
    # Get ML-based optimization
    ml_optimization = ml_engine.optimize_signal_timing(intersection_id, intersection_data, city)
    
    optimization = SignalOptimization(
        intersection_id=intersection_id,
        city=city,
        current_timing=current_timing,
        optimized_timing=ml_optimization["optimized_timing"],
        expected_improvement=ml_optimization["expected_improvement"],
        ai_reasoning=ml_optimization["reasoning"],
        ml_confidence=ml_optimization["ml_confidence"]
    )
    
    # Store in database
    await db.signal_optimizations.insert_one(optimization.dict())
    
    return optimization.dict()

@api_router.get("/ml/predict/{city}/{intersection_id}")
async def predict_traffic_ml(city: str, intersection_id: str, horizon: int = 60):
    """ML-powered traffic prediction for specific intersection"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    try:
        prediction = ml_engine.predict_traffic(city, intersection_id, horizon)
        
        # Store prediction in database
        await db.traffic_predictions.insert_one(prediction.dict())
        
        return prediction.dict()
        
    except ValueError as e:
        raise HTTPException(status_code=404, detail=str(e))
    except Exception as e:
        logger.error(f"ML prediction failed: {e}")
        raise HTTPException(status_code=500, detail="ML prediction service temporarily unavailable")

@api_router.get("/ml/batch-predict/{city}")
async def batch_predict_traffic(city: str, horizon: int = 60):
    """Batch ML predictions for all intersections in a city"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
    predictions = []
    
    for intersection in intersections:
        try:
            prediction = ml_engine.predict_traffic(city, intersection["id"], horizon)
            predictions.append(prediction.dict())
            
            # Store in database
            await db.traffic_predictions.insert_one(prediction.dict())
            
        except Exception as e:
            logger.error(f"Prediction failed for {intersection['id']}: {e}")
            continue
    
    return {
        "city": city,
        "prediction_horizon_minutes": horizon,
        "total_predictions": len(predictions),
        "predictions": predictions,
        "ml_model_info": {
            "accuracy": ml_engine.model_accuracy,
            "is_trained": ml_engine.is_trained
        }
    }

@api_router.get("/ml/model-performance/{city}")
async def get_ml_model_performance(city: str):
    """Get ML model performance metrics"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    if not ml_engine.is_trained:
        # Train models if not already trained
        ml_engine.train_models(city)
    
    return {
        "city": city,
        "model_status": "trained" if ml_engine.is_trained else "not_trained",
        "accuracy_metrics": ml_engine.model_accuracy,
        "models_used": {
            "traffic_prediction": "GradientBoostingRegressor",
            "speed_prediction": "RandomForestRegressor", 
            "congestion_classification": "GradientBoostingRegressor"
        },
        "features_used": [
            "hour", "day_of_week", "is_weekend", "is_rush_hour",
            "is_morning", "is_evening", "weather_impact", "latitude", "longitude"
        ],
        "training_data_size": "30 days of synthetic traffic data"
    }

@api_router.post("/ml/retrain/{city}")
async def retrain_ml_models(city: str):
    """Retrain ML models with latest data"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    try:
        # Retrain models
        ml_engine.train_models(city)
        
        return {
            "status": "success",
            "message": f"ML models retrained successfully for {city}",
            "new_accuracy": ml_engine.model_accuracy,
            "timestamp": datetime.utcnow().isoformat()
        }
        
    except Exception as e:
        logger.error(f"Model retraining failed: {e}")
        raise HTTPException(status_code=500, detail="Model retraining failed")

@api_router.get("/analytics/ml-insights/{city}")
async def get_ml_traffic_insights(city: str):
    """Get advanced ML-powered traffic analytics and insights"""
    if city not in ["Accra", "Kumasi"]:
        raise HTTPException(status_code=400, detail="City must be 'Accra' or 'Kumasi'")
    
    # Generate predictions for next 4 hours
    intersections = ACCRA_INTERSECTIONS if city == "Accra" else KUMASI_INTERSECTIONS
    hourly_predictions = []
    
    for hour in [60, 120, 180, 240]:  # 1, 2, 3, 4 hours ahead
        hour_predictions = []
        for intersection in intersections[:3]:  # Top 3 intersections
            try:
                prediction = ml_engine.predict_traffic(city, intersection["id"], hour)
                hour_predictions.append({
                    "intersection_id": intersection["id"],
                    "name": intersection["name"],
                    "predicted_congestion": prediction.predicted_congestion,
                    "predicted_vehicles": prediction.predicted_vehicle_count,
                    "confidence": prediction.confidence_score
                })
            except Exception as e:
                logger.error(f"Prediction failed: {e}")
                continue
        
        hourly_predictions.append({
            "hour_ahead": hour // 60,
            "predictions": hour_predictions
        })
    
    # Analyze patterns
    current_time = datetime.now()
    is_peak_approaching = any(
        abs(current_time.hour - peak_hour) <= 1 
        for peak_hour in [8, 18]  # Morning and evening peaks
    )
    
    # ML-based insights
    insights = {
        "city": city,
        "timestamp": current_time.isoformat(),
        "ml_predictions": hourly_predictions,
        "pattern_analysis": {
            "peak_approaching": is_peak_approaching,
            "expected_peak_severity": "High" if is_peak_approaching else "Moderate",
            "recommended_actions": [
                "Prepare dynamic signal optimization" if is_peak_approaching else "Monitor traffic patterns",
                "Alert traffic management center" if is_peak_approaching else "Maintain standard operations"
            ]
        },
        "optimization_opportunities": [
            {
                "intersection_id": intersection["id"],
                "opportunity": "Signal timing optimization",
                "potential_improvement": f"{random.randint(15, 35)}% reduction in wait time"
            } for intersection in intersections[:2]
        ],
        "model_reliability": {
            "overall_confidence": sum(ml_engine.model_accuracy.values()) / len(ml_engine.model_accuracy) if ml_engine.model_accuracy else 0.8,
            "prediction_accuracy": "85-92%" if ml_engine.is_trained else "Training required"
        }
    }
    
    return insights

# Include the router in the main app
app.include_router(api_router)

app.add_middleware(
    CORSMiddleware,
    allow_credentials=True,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

@app.on_event("startup")
async def startup_db_client():
    """Initialize database, AI integration, and ML models"""
    logger.info("Starting Traffic Flow Optimization API...")
    
    # Initialize AI chat
    await initialize_ai_chat()
    
    # Create database indexes for better performance
    try:
        await db.traffic_data.create_index("intersection_id")
        await db.traffic_data.create_index("city")
        await db.traffic_data.create_index("timestamp")
        await db.route_recommendations.create_index("timestamp")
        await db.traffic_patterns.create_index("city")
        await db.traffic_predictions.create_index([("city", 1), ("intersection_id", 1)])
        await db.signal_optimizations.create_index("intersection_id")
        logger.info("Database indexes created successfully")
    except Exception as e:
        logger.warning(f"Index creation failed: {e}")
    
    # Pre-train ML models for both cities in background
    async def train_models_background():
        try:
            logger.info("Starting ML model training...")
            ml_engine.train_models("Accra")
            logger.info("ML models trained for Accra")
        except Exception as e:
            logger.error(f"ML model training failed: {e}")
    
    # Start background training (non-blocking)
    asyncio.create_task(train_models_background())

@app.on_event("shutdown")
async def shutdown_db_client():
    client.close()